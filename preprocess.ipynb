{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from fastai.data_block import get_files\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import tensorflow as tf\n",
    "import torch \n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_PATH  = 'yt8m/2/frame/train'\n",
    "OUT_PATH = 'yt8m-processed'\n",
    "\n",
    "files = [str(f) for f in get_files(IN_PATH, '.tfrecord')]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "A_SZ, V_SZ = 128,1024\n",
    "SZ= int(1e7)\n",
    "a = torch.empty((SZ,A_SZ), dtype=torch.uint8) # audio\n",
    "v = torch.empty((SZ,V_SZ), dtype=torch.uint8) # video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_f = i_av = 0\n",
    "for i,raw_record in enumerate(progress_bar(raw_dataset.take(-1), total=3888919)):\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    labels = list(example.context.feature['labels'].int64_list.value)\n",
    "    vid    = str(example.context.feature['id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "    audio  = torch.ByteTensor(\n",
    "        [np.frombuffer(f.bytes_list.value[0], dtype=np.uint8) for f in example.feature_lists.feature_list['audio'].feature])\n",
    "    video  = torch.ByteTensor(\n",
    "        [np.frombuffer(f.bytes_list.value[0], dtype=np.uint8) for f in example.feature_lists.feature_list['rgb'].feature])\n",
    "    frames = len(audio)\n",
    "    assert frames == len(video)\n",
    "    d[vid] = (i_av, frames, labels)\n",
    "    a[i_av:i_av+frames] = audio\n",
    "    v[i_av:i_av+frames] = video\n",
    "    del audio, video, labels\n",
    "    i_av += frames\n",
    "    if (i_av + 300)>= SZ:\n",
    "        print(f'Saving {i_f} at {i}')\n",
    "        torch.save(a[:i_av], f'{OUT_PATH}/a{i_f}.pth')\n",
    "        torch.save(v[:i_av], f'{OUT_PATH}/v{i_f}.pth')\n",
    "        with open(f'{OUT_PATH}/d{i_f}.pkl', 'wb') as handle:\n",
    "            pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        d = dict()\n",
    "        i_av = 0\n",
    "        i_f += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_f = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmap_bytetensor(f, shape, shared=False,size=None):\n",
    "    return torch.ByteTensor(\n",
    "        torch.ByteStorage.from_file(f, shared=shared, size=size if size is not None else os.path.getsize(f))).view(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifnone(v.numel(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in progress_bar(range(89)): # 89\n",
    "    a = torch.load(f'{OUT_PATH}/a{i}.pth')\n",
    "    aw = mmap_bytetensor(f'{OUT_PATH}/a{i}.bin',(-1,128),  shared=True, size=a.numel())\n",
    "    aw[:] = a\n",
    "    v = torch.load(f'{OUT_PATH}/v{i}.pth')\n",
    "    vw = mmap_bytetensor(f'{OUT_PATH}/v{i}.bin',(-1,1024), shared=True, size=v.numel())\n",
    "    vw[:] = v\n",
    "    os.remove(f'{OUT_PATH}/a{i}.pth')\n",
    "    os.remove(f'{OUT_PATH}/v{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvw=read_bytetensor('yt8m-processed/v0.bin', (-1,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 89\n",
    "[read_bytetensor(f'yt8m-processed/v{i}.bin', (-1,1024)) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
