{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from fastai.data_block import get_files\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import tensorflow as tf\n",
    "import torch \n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.data_block import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.train import *\n",
    "from fastai.callback import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.distributed import *\n",
    "from fastai.layers import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l : [item for sublist in l for item in sublist]\n",
    "def to_one_hot(v,c): return torch.zeros((c,)).scatter_(0,v,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_SZ, V_SZ, L_SZ = 128,1024, 300 #303\n",
    "IN_PATH  = 'yt8m-processed'\n",
    "\n",
    "files = sorted([str(f) for f in get_files(IN_PATH, '.pkl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='90' class='' max='90', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [90/90 00:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = dict()\n",
    "for f in progress_bar(files):\n",
    "    with open(f, 'rb') as handle:\n",
    "        _d = pickle.load(handle)\n",
    "    n = int(re.match(r'.*d(\\d+)\\.pkl', f)[1])\n",
    "    fa= re.sub(r'd\\d+\\.pkl', f'a{n}.bin', f) \n",
    "    fv= re.sub(r'd\\d+\\.pkl', f'v{n}.bin', f) \n",
    "    d.update({k: (fa,fv,*v) for k, v in _d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3913565' class='' max='3913565', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3913565/3913565 00:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# process dict to be:\n",
    "# fname_audio, fname_video,start,len,[labels]+,[segment_start,[segment_label,segment_score,]+]+\n",
    "fnames_a,fnames_v = set(), set()\n",
    "val_labels = set()\n",
    "for k,v in progress_bar(d.items()):\n",
    "    if len(v) == 5:\n",
    "        fa,fv,s,e,labels = v\n",
    "        d[k] = fa,fv,s,e,labels,[]\n",
    "    else:\n",
    "        fa,fv,s,e,labels,segments = v\n",
    "        sd = defaultdict(list)\n",
    "        for segment in segments:\n",
    "            s_l,s_s,s_ss,s_se = segment\n",
    "            val_labels.add(s_l)\n",
    "            assert s_se-s_ss == 5\n",
    "            sd[s_ss].append((s_l,s_s))\n",
    "        d[k] = fa,fv,s,e,labels,list(sd.items())\n",
    "    fnames_a.add(fa)\n",
    "    fnames_v.add(fv)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H5Ti',\n",
       " ('yt8m-processed/val_a0.bin',\n",
       "  'yt8m-processed/val_v0.bin',\n",
       "  10793610,\n",
       "  300,\n",
       "  [571],\n",
       "  [(80, [(571, 1.0)]),\n",
       "   (205, [(571, 1.0)]),\n",
       "   (150, [(571, 0.0)]),\n",
       "   (110, [(571, 1.0)]),\n",
       "   (180, [(571, 1.0)])]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.items())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3913565' class='' max='3913565', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3913565/3913565 00:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_labels_l = sorted(val_labels)\n",
    "train_label_to_val = lambda x: val_labels_l.index(x)\n",
    "\n",
    "i = 0\n",
    "# filter items that DO NOT have val_labels, remove labels not in val_labels\n",
    "# and re-reference labels from 0..1000 (using val_labels as index)\n",
    "old_d = d.copy()\n",
    "d = {}\n",
    "for k,v in progress_bar(old_d.items()):\n",
    "    fa,fv,s,e,labels,segments = v\n",
    "    intersection = val_labels.intersection(labels)\n",
    "    if len(intersection)!=0:\n",
    "        new_labels = [train_label_to_val(label) for label in intersection]\n",
    "        new_segments = []\n",
    "        for s_s,s_ll in segments:\n",
    "            new_segments.append((s_s, [(train_label_to_val(s_label),s_score) for s_label,s_score in s_ll]))\n",
    "        d[k]= fa,fv,s,e,new_labels,new_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H5Ti',\n",
       " ('yt8m-processed/val_a0.bin',\n",
       "  'yt8m-processed/val_v0.bin',\n",
       "  10793610,\n",
       "  300,\n",
       "  [316],\n",
       "  [(80, [(316, 1.0)]),\n",
       "   (205, [(316, 1.0)]),\n",
       "   (150, [(316, 0.0)]),\n",
       "   (110, [(316, 1.0)]),\n",
       "   (180, [(316, 1.0)])]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.items())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = flatten([v[4] for v in d.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_V_LABELS = len(np.unique([item for sublist in [v[4] for v in d.values()] for item in sublist]))\n",
    "N_V_LABELS = 1000 # video labels in val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = Tensor(compute_class_weight('balanced', range(N_V_LABELS), all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmap_bytetensor(f, shape, shared=False,size=None):\n",
    "    return torch.ByteTensor(torch.ByteStorage.from_file(\n",
    "        f, shared=shared, size=size if size is not None else os.path.getsize(f))).view(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YTItem(ItemBase):\n",
    "    a = {fa: mmap_bytetensor(fa, (-1,A_SZ)) for fa in fnames_a}\n",
    "    v = {fv: mmap_bytetensor(fv, (-1,V_SZ)) for fv in fnames_v} \n",
    "    \n",
    "    def __init__(self,i): \n",
    "        self.i = i\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        vid, (fname_a,fname_v,idx,l,classes,segments) = self.i\n",
    "        a = torch.zeros((L_SZ,A_SZ), dtype=torch.float32) # audio\n",
    "        v = torch.zeros((L_SZ,V_SZ), dtype=torch.float32) # video  \n",
    "        m = torch.zeros((L_SZ,),     dtype=torch.bool)    # mask\n",
    "        l = min(min(idx+l, YTItem.a[fname_a].shape[0]) - idx, L_SZ)\n",
    "        #l = l // 5 * 5 # multiple of 5\n",
    "        a[:l] = (YTItem.a[fname_a][idx:idx+l].to(dtype=torch.float32))/255 - 0.5\n",
    "        v[:l] = (YTItem.v[fname_v][idx:idx+l].to(dtype=torch.float32))/255 - 0.5\n",
    "        m[l:] = True\n",
    "        return a,v,m,l\n",
    "        \n",
    "    def __str__(self):\n",
    "        # TODO: count n_atoms correctly. \n",
    "        return f'{self.i}'\n",
    "    \n",
    "    def apply_tfms(self, tfms:Collection, **kwargs):\n",
    "        x = self.clone()\n",
    "        for t in tfms:\n",
    "            if t: x.data = t(x.data)\n",
    "        return x\n",
    "    \n",
    "    def clone(self):\n",
    "        return self.__class__(self.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YTLabel(ItemBase):\n",
    "    def __init__(self,labels,segments,**kwargs): \n",
    "        self.labels, self.segments = labels,segments\n",
    "        if len(segments):\n",
    "            lll = flatten([[(o,label,score) for label,score in l ]for (o,l) in segments])\n",
    "            i = torch.LongTensor([(o//5, c)for (o,c,_) in lll])\n",
    "            v = torch.Tensor([s+1 for (_,_,s) in lll]) # 0,1 => 1,2\n",
    "            self.t_segments = torch.sparse.FloatTensor(i.t(), v, torch.Size([1+L_SZ//5,N_V_LABELS]))\n",
    "        else:\n",
    "            self.t_segments = torch.sparse.FloatTensor(torch.LongTensor([[L_SZ//5,0]]).t(), \n",
    "                                                  torch.Tensor([1]),torch.Size([1+L_SZ//5,N_V_LABELS]))\n",
    "        self.t_labels = LongTensor(self.labels)\n",
    "    @property\n",
    "    def data(self):\n",
    "#        return to_one_hot(self.t_labels, N_V_LABELS),self.t_segments.to_dense()\n",
    "        return to_one_hot(self.t_labels, N_V_LABELS)#,self.t_segments.to_dense()\n",
    "    def __str__(self):\n",
    "        return f'{self.labels}, {self.segments}'\n",
    "    def apply_tfms(self, tfms:Collection, **kwargs):\n",
    "        y = self.clone()\n",
    "        for t in tfms:\n",
    "            if t: y.data = t(y.data)\n",
    "        return y\n",
    "    def clone(self): return self.__class__(self.labels, self.segment)\n",
    "    def __hash__(self): return hash(str(self))\n",
    "    \n",
    "class YTLabelList(ItemList):\n",
    "    def __init__(self, items:Iterator, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "\n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        return YTLabel(*o)\n",
    "\n",
    "    def reconstruct(self,t): return 0; # TODO for viz !!!! ScalarCouplingItem(t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ItemList(items=(YTItem(i) for i in d.items()),label_cls=YTLabel).split_by_rand_pct(0.2, seed=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = YTLabel(data.train[2097294-418].i[1][4],data.train[2097294-418].i[1][5]).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll = flatten([[(o,label,score) for label,score in l ]for (o,l) in data.train[2097294-31110].i[1][5]])\n",
    "i = torch.LongTensor([(o//5, c)for (o,c,_) in lll])\n",
    "v = torch.Tensor([s+1 for (_,_,s) in lll])\n",
    "torch.sparse.FloatTensor(i.t(), v, torch.Size([L_SZ//5,N_V_LABELS])).to_dense()[32]-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7, 164],\n",
       "        [ 21, 164],\n",
       "        [  6, 164],\n",
       "        [ 13, 164],\n",
       "        [ 16, 164]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (2097294 items)\n",
       "x: ItemList\n",
       "('sCyE', ('yt8m-processed/a0.bin', 'yt8m-processed/v0.bin', 600, 251, [4], [])),('8gyE', ('yt8m-processed/a0.bin', 'yt8m-processed/v0.bin', 851, 258, [2, 0], [])),('N6yE', ('yt8m-processed/a0.bin', 'yt8m-processed/v0.bin', 1409, 290, [13], [])),('yDyE', ('yt8m-processed/a0.bin', 'yt8m-processed/v0.bin', 1956, 300, [15, 0, 11], [])),('9ryE', ('yt8m-processed/a0.bin', 'yt8m-processed/v0.bin', 2506, 173, [22, 59], []))\n",
       "y: YTLabelList\n",
       "[4], [],[2, 0], [],[13], [],[15, 0, 11], [],[22, 59], []\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (524323 items)\n",
       "x: ItemList\n",
       "('n5DH', ('yt8m-processed/a74.bin', 'yt8m-processed/v74.bin', 9047287, 208, [6, 188], [])),('w3vF', ('yt8m-processed/a1.bin', 'yt8m-processed/v1.bin', 6062249, 162, [14, 3, 192, 9, 56], [])),('RrOe', ('yt8m-processed/a19.bin', 'yt8m-processed/v19.bin', 5969173, 162, [32], [])),('yi0X', ('yt8m-processed/a23.bin', 'yt8m-processed/v23.bin', 3728527, 150, [448], [])),('m823', ('yt8m-processed/a23.bin', 'yt8m-processed/v23.bin', 8585231, 241, [52, 259, 252, 74], []))\n",
       "y: YTLabelList\n",
       "[6, 188], [],[14, 3, 192, 9, 56], [],[32], [],[448], [],[52, 259, 252, 74], []\n",
       "Path: .;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_from_func(lambda x: x.i[1][4:],label_cls=YTLabelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDecoder(Module):\n",
    "    def __init__(self,dropout:float=0):\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,tgt, memory, tgt_mask=None, memory_mask=None, \n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        return self.dropout(memory)\n",
    "    \n",
    "class PositionalEncoding(Module):\n",
    "    \"Encode the position with a sinusoid.\"\n",
    "    def __init__(self, d:int): self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
    "\n",
    "    def forward(self, pos:Tensor):\n",
    "        inp = torch.ger(pos, self.freq)\n",
    "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
    "        return enc\n",
    "    \n",
    "class YTTransformer(Module):\n",
    "    def __init__(self,n_layers,n_heads,d_model,embed_p:float=0,final_p:float=0,d_head=None,deep_decoder=False,\n",
    "                 dense_out=False,recurrent_decoder=False, pos=True, use_audio=True, **kwargs):\n",
    "        \n",
    "        self.use_audio = use_audio\n",
    "        self.d_av = (V_SZ + A_SZ) if self.use_audio else V_SZ\n",
    "        self.d_model = d_model\n",
    "        self.pos = pos\n",
    "        self.recurrent_decoder = recurrent_decoder\n",
    "        d_head = ifnone(d_head, d_model//n_heads)\n",
    "        self.pre_encoder = nn.Linear(self.d_av, d_model)\n",
    "\n",
    "        self.transformer = nn.Transformer(num_encoder_layers=n_layers,\n",
    "                                          nhead=n_heads,d_model=d_model,dim_feedforward=d_inner,\n",
    "                                          dropout = 0., custom_decoder=DummyDecoder(dropout=0.))\n",
    "    \n",
    "        self.pos_enc = PositionalEncoding(d_model) if self.pos else nn.Embedding(L_SZ//5*5, d_model)\n",
    "\n",
    "        if recurrent_decoder:\n",
    "            self.rnn = torch.nn.GRU(d_model, N_V_LABELS)\n",
    "        else:\n",
    "            self.label_pool0   = nn.AdaptiveAvgPool1d(1)\n",
    "            self.label_pool1   = nn.AdaptiveMaxPool1d(1)\n",
    "            self.label_decoder = nn.Linear(d_model*2, N_V_LABELS)\n",
    "\n",
    "        self.segment_pool    = nn.AdaptiveAvgPool1d(L_SZ//5)\n",
    "        self.segment_decoder = nn.Conv1d(d_model, N_V_LABELS,1)\n",
    "    \n",
    "        \n",
    "    def forward(self,a,v,m,l):\n",
    "        bs,l_v,c_v = v.shape\n",
    "        pos = torch.arange(0, L_SZ//5*5, device=v.device, dtype=v.dtype if self.pos else torch.int64)\n",
    "        if self.use_audio: \n",
    "            x = torch.cat([v,a], dim=-1)\n",
    "        else:\n",
    "            x = v\n",
    "        x = self.pre_encoder(x)\n",
    "        x = (x + self.pos_enc(pos)[None]) * math.sqrt(self.d_model)\n",
    "        x.masked_fill_(m.unsqueeze(-1), 0.)\n",
    "        x = x.transpose(0,1)\n",
    "        x = self.transformer(x, x, src_key_padding_mask=None)\n",
    "        if self.recurrent_decoder:\n",
    "            self.rnn.flatten_parameters()\n",
    "            output,labels = self.rnn(x) # \n",
    "            labels = labels.permute(1,2,0).squeeze(-1) # (S, N, H_{out})\n",
    "            x = x.permute(1,2,0)\n",
    "        else:\n",
    "            x = x.permute(1,2,0)\n",
    "            labels = x[:,:,0]\n",
    "#            labels = torch.cat((self.label_pool0(x),self.label_pool1(x)),dim=1).squeeze(-1)\n",
    "#            labels = self.label_decoder(labels)\n",
    "        segments = self.segment_pool(x).squeeze(-1)\n",
    "        segments = self.segment_decoder(segments).squeeze(-1)\n",
    "        \n",
    "        return labels#,segments\n",
    "    \n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(Module):\n",
    "    def __init__(self):\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight=label_weights.cuda())\n",
    "\n",
    "    def forward(self, from_forward, t_labels):#, t_segments):\n",
    "        #p_labels,p_segments= from_forward        \n",
    "        p_labels= from_forward        \n",
    "        return self.loss(p_labels,t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net, learner = None,None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "n_layers=8\n",
    "n_heads=10\n",
    "d_model=N_V_LABELS # V_SZ+A_SZ\n",
    "d_inner=2048\n",
    "\n",
    "deep_decoder = False\n",
    "dense_out = False\n",
    "\n",
    "net = YTTransformer(n_layers=n_layers, n_heads=n_heads,d_model=d_model,d_inner=d_inner,\n",
    "                      resid_p=0., attn_p=0., ff_p=0., embed_p=0, final_p=0.,\n",
    "                      deep_decoder=deep_decoder, dense_out=dense_out, recurrent_decoder=False)\n",
    "\n",
    "learner = Learner(data,net,loss_func=MaskedLoss()).to_fp32()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YTTransformer\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Linear               [300, 1000]          1,153,000  True      \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 2048]            2,050,048  True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 2048]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [1, 1000]            2,049,000  True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [1, 1000]            2,000      True      \n",
       "______________________________________________________________________\n",
       "Dropout              [1, 1000]            0          False     \n",
       "______________________________________________________________________\n",
       "PositionalEncoding   [1000]               0          False     \n",
       "______________________________________________________________________\n",
       "AdaptiveAvgPool1d    [1000, 60]           0          False     \n",
       "______________________________________________________________________\n",
       "Conv1d               [1000, 60]           1,001,000  True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 34,980,384\n",
       "Total trainable params: 34,980,384\n",
       "Total non-trainable params: 0\n",
       "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : MaskedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YTTransformer(\n",
       "  (pre_encoder): Linear(in_features=1152, out_features=1000, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1000, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "          (norm1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): DummyDecoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (pos_enc): PositionalEncoding()\n",
       "  (label_pool0): AdaptiveAvgPool1d(output_size=1)\n",
       "  (label_pool1): AdaptiveMaxPool1d(output_size=1)\n",
       "  (label_decoder): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  (segment_pool): AdaptiveAvgPool1d(output_size=60)\n",
       "  (segment_decoder): Conv1d(1000, 1000, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load('1k-3epochs-0.011183',strict=False,with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learner.to_parallel()#loss_scale=128, dynamic=False)\n",
    "data.batch_size = (16+8) * torch.cuda.device_count()\n",
    "data.batch_size *= int(any([isinstance(cb, MixedPrecision) for cb in learner.callbacks]))+1 # 2x if fp16 1x otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'models/bestmodel.pth': No such file or directory\r\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 7.59E-01\n",
      "Min loss divided by 10: 3.31E-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm models/bestmodel.pth\n",
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='858' class='' max='29129', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.95% [858/29129 08:44<4:48:17 0.0145]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_fc(1, 4e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('1k-3epochs-0.011183')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = learner.get_preds(DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in progress_bar(\n",
    "    enumerate(learner.dl(DatasetType.Train)), total=len(learner.dl(DatasetType.Train))):\n",
    "    p = learner.pred_batch(DatasetType.Train, batch=batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200): print(torch.argmax(p[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(p[23][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(torch.sigmoid(p[1])>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
